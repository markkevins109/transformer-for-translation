{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf0c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6b0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranining Hyperparameters\n",
    "batch_size = 64\n",
    "\n",
    "# Model Hyperparameters\n",
    "embed_dim = 128\n",
    "num_heads = 10\n",
    "latent_dim = 2048\n",
    "vocab_size = 20000\n",
    "sequence_length = 20\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315fa63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # Lowercase the characters\n",
    "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : x.lower())\n",
    "    df[\"hindi_sent\"] = df[\"hindi_sent\"].apply(lambda x : x.lower())\n",
    "\n",
    "    # Rmoving URLs\n",
    "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n",
    "    df[\"hindi_sent\"] = df[\"hindi_sent\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n",
    "\n",
    "    # Removing digits\n",
    "    remove_digits = str.maketrans(\"\", \"\",string.digits)\n",
    "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : x.translate(remove_digits))\n",
    "    df[\"hindi_sent\"] = df[\"hindi_sent\"].apply(lambda x : x.translate(remove_digits))\n",
    "    df[\"hindi_sent\"] = df[\"hindi_sent\"].apply(lambda x : re.sub(\"[a-zA-z२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "    # Remove special characters\n",
    "    special = set(string.punctuation)\n",
    "    df['english_sent'] = df['english_sent'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n",
    "    df['hindi_sent'] = df['hindi_sent'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n",
    "\n",
    "    # Remove quotes\n",
    "    df['english_sent'] = df['english_sent'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "    df['hindi_sent'] = df['hindi_sent'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "    # Remove extra spaces\n",
    "    df['english_sent'] = df['english_sent'].apply(lambda x : x.strip())\n",
    "    df['hindi_sent'] = df['hindi_sent'].apply(lambda x : x.strip())\n",
    "    df['english_sent'] = df['english_sent'].apply(lambda x : re.sub(\" +\",\" \",x))\n",
    "    df['hindi_sent'] = df['hindi_sent'].apply(lambda x : re.sub(\" +\",\" \",x))\n",
    "\n",
    "\n",
    "    # Add [start] and [end] tags\n",
    "    df[\"hindi_sent\"] = df[\"hindi_sent\"].apply(lambda x : \"[start] \" + x + \" [end]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2070d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sentence):\n",
    "    hindi_vocab = hindi_vectorization.get_vocabulary()\n",
    "    hindi_index_lookup = dict(zip(range(len(hindi_vocab)), hindi_vocab))\n",
    "    max_decoded_sentence_length = 20\n",
    "\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = hindi_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = hindi_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    return decoded_sentence[8:-5] # Removing [start] and [end] tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93e1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating Dataset\n",
    "def format_dataset(eng, hin):\n",
    "    eng = eng_vectorization(eng)\n",
    "    hindi = hindi_vectorization(hin)\n",
    "    return ({\"encoder_inputs\" : eng, \"decoder_inputs\" : hindi[:, :-1],}, hindi[:, 1:])\n",
    "\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"english_sent\"].values, df[\"hindi_sent\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6335e82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sent</th>\n",
       "      <th>hindi_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english_sent  \\\n",
       "0  politicians do not have permission to do what ...   \n",
       "1         I'd like to tell you about one such child,   \n",
       "2  This percentage is even greater than the perce...   \n",
       "3  what we really mean is that they're bad at not...   \n",
       "4  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                          hindi_sent  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"C:\\Users\\mark kevin\\Downloads\\Hindi_English_Truncated_Corpus.csv\"\n",
    "df=pd.read_csv(path)\n",
    "df.drop([\"source\"], axis=1, inplace = True)\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.rename(columns = {\"english_sentence\" : \"english_sent\", \"hindi_sentence\" : \"hindi_sent\"}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97050a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "preprocess_text(df)\n",
    "\n",
    "# Drop rows with Null values\n",
    "df.drop(df[df[\"english_sent\"] == \" \"].index, inplace = True)\n",
    "df.drop(df[df[\"hindi_sent\"] == \"[start]  [end]\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd5e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Sentence Length\n",
    "df[\"eng_sent_length\"] = df[\"english_sent\"].apply(lambda x : len(x.split(' ')))\n",
    "df[\"hindi_sent_length\"] = df[\"hindi_sent\"].apply(lambda x : len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9924dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentences with specific length 20\n",
    "df = df[df[\"eng_sent_length\"] <= 20]\n",
    "df = df[df[\"hindi_sent_length\"] <= 20]\n",
    "\n",
    "# Take 85K records for training\n",
    "df = df.sample(n = 85000, random_state = 2048)\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "# Defining train, valid, test\n",
    "train = df.iloc[:80000]\n",
    "val = df.iloc[80000:84500]\n",
    "test = df.iloc[84500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786a0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TextVectorization to create sentence vectors\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length\n",
    "    )\n",
    "\n",
    "hindi_vectorization = TextVectorization(\n",
    "    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length + 1, standardize=custom_standardization\n",
    ")\n",
    "\n",
    "eng_vectorization.adapt(df[\"english_sent\"].values)\n",
    "hindi_vectorization.adapt(df[\"hindi_sent\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2257cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savng parameters and weights of both vectorizer\n",
    "pickle.dump({'config': eng_vectorization.get_config(),\n",
    "             'weights': eng_vectorization.get_weights()}\n",
    "            , open(\"eng_vectorizer.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump({'config': hindi_vectorization.get_config(),\n",
    "             'weights': hindi_vectorization.get_weights()}\n",
    "            , open(\"hindi_vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd89310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train)\n",
    "val_ds = make_dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9082fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_len, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.sequence_len = sequence_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_embedding = layers.Embedding(\n",
    "            input_dim = vocab_size, output_dim = embed_dim\n",
    "        )\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim = sequence_len, output_dim = embed_dim\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embedding(inputs)\n",
    "        embedded_positions = self.position_embedding(positions)\n",
    "        embedded_sum = embedded_tokens + embedded_positions\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, dtype=tf.float32)\n",
    "            mask = tf.expand_dims(mask, axis=-1)\n",
    "            mask = tf.expand_dims(mask, axis=-1)\n",
    "            embedded_sum *= mask\n",
    "\n",
    "        return embedded_sum\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a027053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, dropout, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.layer_norm1 = layers.LayerNormalization()\n",
    "        self.layer_norm2 = layers.LayerNormalization()\n",
    "        self.layer_ffn = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"),\n",
    "             layers.Dropout(dropout),\n",
    "             layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # Handle the mask\n",
    "        if mask is not None:\n",
    "            # Ensure the mask has the correct dimensions\n",
    "            padding_mask = tf.cast(mask, dtype=tf.float32)\n",
    "            padding_mask = padding_mask[:, tf.newaxis, tf.newaxis, :]  # Adjust dimensions for attention\n",
    "\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        # Attention layer\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        ffn_input = self.layer_norm1(inputs + attention_output)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.layer_ffn(ffn_input)\n",
    "        return self.layer_norm2(ffn_input + ffn_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd570e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.attention1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.layer_ffn = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"),\n",
    "             layers.Dropout(dropout),\n",
    "             layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layer_norm1 = layers.LayerNormalization()\n",
    "        self.layer_norm2 = layers.LayerNormalization()\n",
    "        self.layer_norm3 = layers.LayerNormalization()\n",
    "\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        # Generate causal mask\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        \n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask, dtype=tf.float32)\n",
    "            padding_mask = tf.minimum(padding_mask[:, tf.newaxis, :], causal_mask)\n",
    "        else:\n",
    "            padding_mask = causal_mask\n",
    "\n",
    "        # First attention block\n",
    "        attention_output1 = self.attention1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out1 = self.layer_norm1(inputs + attention_output1)\n",
    "\n",
    "        # Second attention block\n",
    "        attention_output2 = self.attention2(\n",
    "            query=out1, value=encoder_outputs, key=encoder_outputs, attention_mask=padding_mask\n",
    "        )\n",
    "        out2 = self.layer_norm2(out1 + attention_output2)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.layer_ffn(out2)\n",
    "        return self.layer_norm3(out2 + ffn_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=tf.float32)\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d56dfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads, dropout,name=\"encoder_1\")(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads, dropout,name=\"decoder_1\")(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c429012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ positional_embedding_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_1                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,186,304</span> │ positional_embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,988,448</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ positional_embedding_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m2,562,560\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_1                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m1,186,304\u001b[0m │ positional_embedding_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_8 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)       │       \u001b[38;5;34m6,988,448\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,737,312</span> (40.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,737,312\u001b[0m (40.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,737,312</span> (40.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,737,312\u001b[0m (40.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ea5a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1142s\u001b[0m 902ms/step - accuracy: 0.5971 - loss: 2.9052 - val_accuracy: 0.6310 - val_loss: 2.4869 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2014888aad0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining callback functions\n",
    "early_stopping = EarlyStopping(patience = 5,restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "\n",
    "# Compiling model\n",
    "transformer.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Training model\n",
    "transformer.fit(train_ds, epochs =1, validation_data = val_ds, callbacks = [early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c551cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Sentence :  how are you\n",
      "Translated Sentence :  आप क्या हैं \n"
     ]
    }
   ],
   "source": [
    "eng = \"how are you\"\n",
    "print(\"English Sentence : \",eng)\n",
    "print(\"Translated Sentence : \",decode_sequence(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9c7c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "transformer.save(\"eng-hin_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c53e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
